{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the choice of preprocessing strategies matters: Botvinik-Nezer, R., Holzmeister, F., Camerer, C.F. et al. Variability in the analysis of a single neuroimaging dataset by many teams. Nature (2020). https://doi.org/10.1038/s41586-020-2314-9. From the abstract: \"The flexibility of analytical approaches is exemplified by the fact that no two teams chose identical workflows to analyse the data. This flexibility resulted in sizeable variation in the results of hypothesis tests, even for teams whose statistical maps were highly correlated at intermediate stages of the analysis pipeline....Our findings show that analytical flexibility can have substantial effects on scientific conclusions, and identify factors that may be related to variability in the analysis of functional magnetic resonance imaging. The results emphasize the importance of validating and sharing complex analysis workflows, and demonstrate the need for performing and reporting multiple analyses of the same data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRIPrep\n",
    "I know I said I wasn't going to cover fmriprep last week, but I changed my mind. Here's how to do it, but after I cover this we'll dive into each step more deeply.  \n",
    "What is fMRIPrep? \"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input.\" It's a big black box that takes a bids dataset and spits out preprocessed data.  \n",
    "fMRIprep's web site is here: https://fmriprep.readthedocs.io/en/stable/index.html  \n",
    "# Installing fMRIprep\n",
    "There are multiple ways to install fMRIprep, but since we are on a HPC cluster we're going to run it in a singularity container. Singularity is installed on talapas, but you'll need to build the fMRIprep container yourself. That will look like this:    \n",
    "```\n",
    "module load singularity\n",
    "singularity build PATHNAME/fmriprep-VERSION.simg docker://poldracklab/fmriprep:VERSION\n",
    "```\n",
    "We need to define two thing: the path where you are going to store the container, and the version of fMRIprep we wish to install. According to https://fmriprep.readthedocs.io/en/stable/changes.html the latest version is 20.0.7. For the path, choose something under your pirg project directory. There won't be room for it under your home directory on talapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypirg = 'lcni' # change this to your own pirg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pirg_path = pathlib.Path().home() / mypirg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure you did that right\n",
    "pirg_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a directory for singularity images, if you don't have one already\n",
    "image_path = pirg_path / 'sing_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path.mkdir(exist_ok = True) # create the directory, don't give an error if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which version we'll build\n",
    "version = '20.0.7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick reminder of how string formating works in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'directory is /home/jolinda/lcni/sing_images, version is 20.0.7'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'directory is {0}, version is {1}'.format(image_path, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our build command is\n",
    "build_command = 'singularity build {0}/fmriprep-{1}.simg docker://poldracklab/fmriprep:{1}'.format(image_path, version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building will take a while, let's use slurmpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slurmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=build_fmriprep\n",
      "#SBATCH --account=lcni\n",
      "\n",
      "module load singularity\n",
      "singularity build /home/jolinda/lcni/sing_images/fmriprep-20.0.7.simg docker://poldracklab/fmriprep:20.0.7\n"
     ]
    }
   ],
   "source": [
    "job = slurmpy.SlurmJob()\n",
    "job.account = mypirg\n",
    "job.jobname = 'build_fmriprep'\n",
    "\n",
    "# remember, slurmpy takes the commands as a list of strings\n",
    "job.command = list()\n",
    "job.command.append('module load singularity')\n",
    "job.command.append(build_command)\n",
    "\n",
    "job.WriteSlurmFile()\n",
    "job.PrintSlurmFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 11949409\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'11949409'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.SubmitSlurmFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIRTY-SEVEN MINUTES LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED 1\n"
     ]
    }
   ],
   "source": [
    "job.ShowStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm-11949409.out\n",
      "\u001b[34mINFO:   \u001b[0m Starting build...\n",
      "Getting image source signatures\n",
      "Skipping fetch of repeat blob sha256:0a01a72a686c389637334de1e2d0012da298960366f6d8f358b8e10dc3b5e330\n",
      "Skipping fetch of repeat blob sha256:cc899a5544da1a6cfb970d2484d32c063f8df26a430d92f39c98e72261e226f2\n",
      "Skipping fetch of repeat blob sha256:19197c55075519928dd2ff059745665a2c9b72f4e8af6f7a1ce662e696d339bd\n",
      "Skipping fetch of repeat blob sha256:716d454e56b61d1343a01f3b1829574333e2e3df20e77d1958d7b0b939ea1b61\n",
      "Skipping fetch of repeat blob sha256:b5bf898e214a893171c1e1ab287fc7f1d3573e414869f21f06e3468fea43add3\n",
      "Skipping fetch of repeat blob sha256:42da0942cc0e3de8b86ba649f506f3a0c87533451756c51d7b8bf181ba94a2eb\n",
      "Skipping fetch of repeat blob sha256:14f5757104e98f3e93ab8930b4afd4eb21146c829f97cb5f942f31f67419dfc1\n",
      "Skipping fetch of repeat blob sha256:611fe4f705a58c51fd740b790122f3f5900386b72f3a4c5bed2f8bd6b5c28a19\n",
      "Skipping fetch of repeat blob sha256:ac0b78389510ddc5f05baf66cce3660bd59dcc6c40f868b039805e42f61755fb\n",
      "Skipping fetch of repeat blob sha256:9e499ad45d567b53c6c6b5a72f4b2d7b37da99751cbc4368d244f517c8951e4d\n",
      "Skipping fetch of repeat blob sha256:7abb3d638ec4853b85fef7192689023a3d394b78198bd8e7894e3857106687a7\n",
      "Skipping fetch of repeat blob sha256:a0f74950c55bb6b072add5997c5b4693182d82bcbd58f000cb1bf107419ce0e4\n",
      "Skipping fetch of repeat blob sha256:759836a2d54d95423af6e30fd1947ce82ea3a4ca8214c41cbb0a8d08529a6d11\n",
      "Skipping fetch of repeat blob sha256:f7867020ff2ce265c91fbaa2ed9caff9f4ec36412796c9f8ed19829f938aca29\n",
      "Skipping fetch of repeat blob sha256:b21d5cc69c8fb02df67725712134ad6d7123d9cea585dc524c5ba03734435000\n",
      "Skipping fetch of repeat blob sha256:8de46f1b04d0fae16915dcc8896d1af6354601a8602be7435f6c5a3446b6830c\n",
      "Skipping fetch of repeat blob sha256:a82cc7ba20ad040d1ae6b0e1e53bee7fc72d53707b992fb6f8f1e5a7aac35a2a\n",
      "Skipping fetch of repeat blob sha256:4a5a32a8b67f8f0d427ade65f52b063bd6e7ba448e5bdfda3e3da19f68369ff5\n",
      "Skipping fetch of repeat blob sha256:557abc17033b8821a4f11bb7a28128494c6d5fc2a98a1e08150eba991ef0a6f4\n",
      "Skipping fetch of repeat blob sha256:b859591002b6d9f24b9df7427b56290084866a327b33c92d5a43aa13a6327b49\n",
      "Skipping fetch of repeat blob sha256:6edc3dbfa58b694e256440b2ddd4d059f6865fd4e6e9a060a3079532098fd0e7\n",
      "Skipping fetch of repeat blob sha256:d2d7bb23d4666b3a682b90f620666f9c7b0ba8e4fa7fc70e41063c145ac4c0fd\n",
      "Skipping fetch of repeat blob sha256:1b4ea68affcaa3782f729d3966d6744c1d83d6a96635c523a347abdc45f16eff\n",
      "Skipping fetch of repeat blob sha256:8585367c1656fcd3acb4f0bb5246cd946754ae66653fbf7421b025ec5d5d343e\n",
      "Skipping fetch of repeat blob sha256:d5059604e0c7aeef1035f904135d5a3158dc4479aa6b181d69d6dee5365c1a91\n",
      "Skipping fetch of repeat blob sha256:93b760a6786466dd44463b90c423a4e880858333f7bbf8728da7d6a9e2cf5d21\n",
      "Skipping fetch of repeat blob sha256:a40c808ff7d99ca3a8c2b986d90de77435a351d0bca0d02df2933670e0d79c6d\n",
      "Copying config sha256:9a95178e8e022218d3233d6e860f4cc1f73ee66ee589d6694c36a13fadb5d8d2\n",
      "\n",
      " 0 B / 17.69 KiB \n",
      " 17.69 KiB / 17.69 KiB  0s\n",
      "Writing manifest to image destination\n",
      "Storing signatures\n",
      "\u001b[34mINFO:   \u001b[0m Creating SIF file...\n",
      "\u001b[34mINFO:   \u001b[0m Build complete: /home/jolinda/lcni/sing_images/fmriprep-20.0.7.simg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job.ShowOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JobID                   JobName  Partition      State    Elapsed     MaxRSS \n",
      "-------------------- ------------------------- ---------- ---------- ---------- ---------- \n",
      "            11949409            build_fmriprep      short  COMPLETED   00:36:47            \n",
      "      11949409.batch                     batch             COMPLETED   00:36:47    302964K \n",
      "     11949409.extern                    extern             COMPLETED   00:36:47          0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job.JobInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmriprep = image_path / 'fmriprep-{}.simg'.format(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmriprep.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test this, you can go into a talapas shell and run the following commands:\n",
    "```\n",
    "module load singularity\n",
    "singularity shell --cleanenv {path to fmriprep image}\n",
    "```\n",
    "This will open a singularity shell with a clean environment. You'll be inside the current working directory. Exit by typing 'exit'.  \n",
    "We can also check it from within the notebook using \"singularity exec {bash command}\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.PythonAndJupyterNotebook.ipynb\n",
      "7.ExaminingData.ipynb\n",
      "8.fmriprep.ipynb\n",
      "CopyTheseCommands.ipynb\n",
      "Untitled.ipynb\n",
      "Untitled1.ipynb\n",
      "Untitled2.ipynb\n",
      "Untitled3.ipynb\n",
      "Untitled4.ipynb\n",
      "Untitled5.ipynb\n",
      "intro_to_python_teaching.ipynb\n",
      "mynotebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {str(fmriprep)} \n",
    "module load singularity \n",
    "singularity exec --cleanenv $1 ls *.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running fmriprep with singularity\n",
    "To run fmriprep with a single subject, we'll use this command:\n",
    "```\n",
    "singularity run --cleanenv {bidsdir} {outputdir} participant --participant-label {label}\n",
    "```\n",
    "'label' is your subject label NOT include sub-. Let's define our bids and output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidsdir = pathlib.Path('/projects/lcni/jolinda/shared/TalapasClass/ds000114/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = pirg_path / 'fmriprep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we try to run fmriprep now? Two errors: first, it won't be able to access those directories. How do I know this? Try this (FYI I'm using '--no-raise-error' with the %%bash magic to only show the std error output, not the big long python error we'd normally see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/projects/lcni/jolinda/shared/TalapasClass/ds000114': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {str(fmriprep)} {str(bidsdir)} --no-raise-error\n",
    "module load singularity \n",
    "singularity exec --cleanenv $1 ls $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That path does not exist in our singularity instance! We need to either define it relative to the current working directory, or use the singularity 'bind' command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGES\n",
      "dataset_description.json\n",
      "dwi.bval\n",
      "dwi.bvec\n",
      "participants.tsv\n",
      "sub-01\n",
      "sub-02\n",
      "sub-03\n",
      "sub-04\n",
      "sub-05\n",
      "sub-06\n",
      "sub-07\n",
      "sub-08\n",
      "sub-09\n",
      "sub-10\n",
      "task-covertverbgeneration_bold.json\n",
      "task-covertverbgeneration_events.tsv\n",
      "task-fingerfootlips_bold.json\n",
      "task-fingerfootlips_events.tsv\n",
      "task-linebisection_bold.json\n",
      "task-overtverbgeneration_bold.json\n",
      "task-overtverbgeneration_events.tsv\n",
      "task-overtwordrepetition_bold.json\n",
      "task-overtwordrepetition_events.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {str(fmriprep)} {str(bidsdir)} --no-raise-error\n",
    "module load singularity \n",
    "singularity exec --cleanenv --bind $2:/bids --cleanenv $1 ls /bids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to specify the bids directory, the output directory and a work directory. If we don't specify a work directory fmriprep will create one under the current working directory. This will be a problem if you're currently in your home directory, because you'll run out of space. First make a work directory somewhere. I'm putting it in the pirg_dir, which I'll bind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = pirg_path / 'work'\n",
    "workdir.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need one last thing: a freesurfer license file. Otherwise fmriprep will fail when it gets to that stage. They are free, you can get one by registering on the freesurfer web site, or there's one in the class directory you can use. It needs to be somewhere fmriprep can find it, for example, in pirg_path. Copying files is a little easier in bash than python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp '/projects/lcni/jolinda/shared/TalapasClass/license.txt' {pirg_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bind multiple directories by separating them with commas, (no spaces). Let's check that we can find the fmriprep and work directories and the freesurfer license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank\n",
      "fmriprep\n",
      "license.txt\n",
      "shared\n",
      "sing_images\n",
      "temp\n",
      "work\n"
     ]
    }
   ],
   "source": [
    "%%bash -s {str(fmriprep)} {str(bidsdir)} {str(pirg_path)} --no-raise-error\n",
    "module load singularity \n",
    "singularity exec --cleanenv --bind $2:/bids,$3:/pirg --cleanenv $1 ls /pirg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our command looks like (using \\ to break up long lines):\n",
    "```\n",
    "singularity run --cleanenv \\\n",
    "--bind {bidsdir}:/bids,{pirg_path}:/pirg \\\n",
    "/bids /pirg/fmriprep \\\n",
    "participant --participant-label -01 \\\n",
    "--work-dir=/pirg/work \\\n",
    "--fs-license-file=/pirg/license.txt\n",
    "```\n",
    "\n",
    "I'm going to add two more options: --nthreads N and --sloppy. Using additional threads will speed things up considerably for things that can take advantage of it and fmriprep is one of those things (I know that freesurfer is multithreaded, I don't know about the rest of it). On talapas there are 28 cores per cpu, so we could use up to 28 threads. I used 8 threads here, feel free to use more. 'sloppy' is good for testing whether your pipeline runs without errors. It'll be faster than the \"real\" analysis by roughly a factor of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module load singularity\n",
      "singularity run --cleanenv \\\n",
      "--bind /projects/lcni/jolinda/shared/TalapasClass/ds000114:/bids,/home/jolinda/lcni:/pirg /home/jolinda/lcni/sing_images/fmriprep-20.0.7.simg \\\n",
      "/bids /pirg/fmriprep participant --participant-label 01 \\\n",
      "--work-dir=/pirg/work \\\n",
      "--fs-license-file=/pirg/license.txt \\\n",
      "--sloppy --nthreads=8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nthreads = 8\n",
    "fmriprep_command = list()\n",
    "fmriprep_command.append('module load singularity')\n",
    "fmriprep_command.append('singularity run --cleanenv \\\\')\n",
    "fmriprep_command.append('--bind {}:/bids,{}:/pirg {} \\\\'.format(bidsdir, pirg_path, fmriprep))\n",
    "fmriprep_command.append('/bids /pirg/fmriprep participant --participant-label 01 \\\\')\n",
    "fmriprep_command.append('--work-dir=/pirg/work \\\\')\n",
    "fmriprep_command.append('--fs-license-file=/pirg/license.txt \\\\')\n",
    "fmriprep_command.append('--sloppy --nthreads={}'.format(nthreads))\n",
    "[print(x) for x in fmriprep_command]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know from past runs that fmriprep will take around 5G of ram and, will complete in 4.5 hours with these parameters (remove 'sloppy' and it will take 7.5 hours). So the default short partition is fine, and so is the default memory allocation (a little more than 4G per cpu). Note that if we weren't requesting more threads, we would need to request more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = slurmpy.SlurmJob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.jobname = 'fmriprep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.account = mypirg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using threads you need to include that in the sbatch parameters\n",
    "# this sets the 'cpus-per-task' parameter\n",
    "# We can't say job.cpus-per-task = nthreads because we can't have dashes inside python variable names, \n",
    "# so this is one of our \"special\" parameters\n",
    "job.threads = nthreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.command = fmriprep_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fmriprep.srun'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.WriteSlurmFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=fmriprep\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --account=lcni\n",
      "\n",
      "module load singularity\n",
      "singularity run --cleanenv \\\n",
      "--bind /projects/lcni/jolinda/shared/TalapasClass/ds000114:/bids,/home/jolinda/lcni:/pirg /home/jolinda/lcni/sing_images/fmriprep-20.0.7.simg \\\n",
      "/bids /pirg/fmriprep participant --participant-label 01 \\\n",
      "--work-dir=/pirg/work \\\n",
      "--fs-license-file=/pirg/license.txt \\\n",
      "--sloppy --nthreads=8\n"
     ]
    }
   ],
   "source": [
    "job.PrintSlurmFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can submit that with job.SubmitSlurmFile(). What if we want to run it on all of our subjects? We need an array of participant labels. Remember pathlib's built in globbing from last week? This time we'll use glob, not relative glob (rglob), because I want to match just the sub- directories directly under the top level bids-dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-01'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-02'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-03'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-04'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-05'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-06'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-07'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-08'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-09'),\n",
       " PosixPath('/projects/lcni/jolinda/shared/TalapasClass/ds000114/sub-10')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bidsdir.glob('sub-*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-03',\n",
       " 'sub-08',\n",
       " 'sub-02',\n",
       " 'sub-07',\n",
       " 'sub-01',\n",
       " 'sub-06',\n",
       " 'sub-05',\n",
       " 'sub-04',\n",
       " 'sub-09',\n",
       " 'sub-10']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.name for x in bidsdir.glob('sub-*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the first four characters: 'sub-', and sort\n",
    "sorted([x.name[4:] for x in bidsdir.glob('sub-*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we have a command that should work for ANY bids directory. Let's modify our job to use an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.array = sorted([x.name[4:] for x in bidsdir.glob('sub-*')])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I'm going to increase the number of threads, drop 'sloppy', and replace the participant label with ${x}. Incidentally if you combine ${x} and .format() in the same string, python is unhappy -- you'd need to double the brackets around the x like this: ${{x}}. If you didn't notice it before, I'm also doubling the '\\' symbols at the end of each line for a similar reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp '/projects/lcni/jolinda/shared/TalapasClass/license.txt' license.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nthreads = 16\n",
    "fmriprep_command = list()\n",
    "fmriprep_command.append('module load singularity')\n",
    "fmriprep_command.append('singularity run --cleanenv \\\\')\n",
    "fmriprep_command.append('--bind {}:/bids,{}:/pirg {} \\\\'.format(bidsdir, pirg_path, fmriprep))\n",
    "fmriprep_command.append('/bids /pirg/fmriprep participant --participant-label ${x} \\\\')\n",
    "fmriprep_command.append('--work-dir=/pirg/work \\\\')\n",
    "fmriprep_command.append('--fs-license-file=/pirg/license.txt \\\\')\n",
    "fmriprep_command.append('--nthreads={}'.format(nthreads))\n",
    "\n",
    "job.threads = nthreads\n",
    "job.command = fmriprep_command\n",
    "job.jobname = 'fprep_array'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fprep_array.srun'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.WriteSlurmFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=fprep_array\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --account=lcni\n",
      "#SBATCH --array=0-9\n",
      "\n",
      "data=(01 02 03 04 05 06 07 08 09 10)\n",
      "\n",
      "x=${data[$SLURM_ARRAY_TASK_ID]}\n",
      "\n",
      "\n",
      "module load singularity\n",
      "singularity run --cleanenv \\\n",
      "--bind /projects/lcni/jolinda/shared/TalapasClass/ds000114:/bids,/home/jolinda/lcni:/pirg /home/jolinda/lcni/sing_images/fmriprep-20.0.7.simg \\\n",
      "/bids /pirg/fmriprep participant --participant-label ${x} \\\n",
      "--work-dir=/pirg/work \\\n",
      "--fs-license-file=/pirg/license.txt \\\n",
      "--nthreads=16\n"
     ]
    }
   ],
   "source": [
    "job.PrintSlurmFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 11988466\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'11988466'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.SubmitSlurmFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED 1\n",
      "RUNNING 9\n"
     ]
    }
   ],
   "source": [
    "job.ShowStatus()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "which one failed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               JobID                   JobName  Partition      State    Elapsed     MaxRSS \n",
      "-------------------- ------------------------- ---------- ---------- ---------- ---------- \n",
      "          11988466_0               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_0.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_0.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_1               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_1.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_1.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_2               fprep_array      short     FAILED   00:00:12            \n",
      "    11988466_2.batch                     batch                FAILED   00:00:12          0 \n",
      "   11988466_2.extern                    extern             COMPLETED   00:00:12          0 \n",
      "          11988466_3               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_3.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_3.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_4               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_4.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_4.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_5               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_5.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_5.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_6               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_6.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_6.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_7               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_7.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_7.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_8               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_8.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_8.extern                    extern               RUNNING   00:00:28            \n",
      "          11988466_9               fprep_array      short    RUNNING   00:00:28            \n",
      "    11988466_9.batch                     batch               RUNNING   00:00:28            \n",
      "   11988466_9.extern                    extern               RUNNING   00:00:28            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(job.JobInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm-11988466_2.out\n",
      "bids-validator@1.4.0\n",
      "\n",
      "\t\u001b[31m1: [ERR] Files with such naming scheme are not part of BIDS specification. This error is most commonly caused by typos in file names that make them not BIDS compatible. Please consult the specification and make sure your files are named correctly. If this is not a file naming issue (for example when including files not yet covered by the BIDS specification) you should include a \".bidsignore\" file in your dataset (see https://github.com/bids-standard/bids-validator#bidsignore for details). Please note that derived (processed) data should be placed in /derivatives folder and source data (such as DICOMS or behavioural logs in proprietary formats) should be placed in the /sourcedata folder. (code: 1 - NOT_INCLUDED)\u001b[39m\n",
      "\t\t./sub-03/ses-test/func/sub-03_ses-test_task-linebisection_bold.nii.gz.crswap\n",
      "\t\t\tEvidence: sub-03_ses-test_task-linebisection_bold.nii.gz.crswap\n",
      "\n",
      "\u001b[36m\tPlease visit https://neurostars.org/search?q=NOT_INCLUDED for existing conversations about this issue.\u001b[39m\n",
      "\n",
      "\t\u001b[31m2: [ERR] Empty files not allowed. (code: 99 - EMPTY_FILE)\u001b[39m\n",
      "\t\t./sub-03/ses-test/func/sub-03_ses-test_task-linebisection_bold.nii.gz.crswap\n",
      "\n",
      "\u001b[36m\tPlease visit https://neurostars.org/search?q=EMPTY_FILE for existing conversations about this issue.\u001b[39m\n",
      "\n",
      "\t\u001b[33m1: [WARN] The recommended file /README is missing. See Section 03 (Modality agnostic files) of the BIDS specification. (code: 101 - README_FILE_MISSING)\u001b[39m\n",
      "\n",
      "\u001b[36m\tPlease visit https://neurostars.org/search?q=README_FILE_MISSING for existing conversations about this issue.\u001b[39m\n",
      "\n",
      "\n",
      "        \u001b[34m\u001b[4mSummary:\u001b[24m\u001b[39m                 \u001b[34m\u001b[4mAvailable Tasks:\u001b[24m\u001b[39m              \u001b[34m\u001b[4mAvailable Modalities:\u001b[24m\u001b[39m \n",
      "        175 Files, 4.34GB        covert_verb_generation        T1w                   \n",
      "        10 - Subjects            finger_foot_lips              dwi                   \n",
      "        2 - Sessions             line_bisection                bold                  \n",
      "                                 overt_word_repetition         events                \n",
      "                                 overt_verb_generation                               \n",
      "\n",
      "\n",
      "\u001b[36m\tIf you have any questions, please post on https://neurostars.org/tags/bids.\u001b[39m\n",
      "\n",
      "Making sure the input data is BIDS compliant (warnings can be ignored in most cases).\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/miniconda/bin/fmriprep\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/miniconda/lib/python3.7/site-packages/fmriprep/cli/run.py\", line 319, in main\n",
      "    validate_input_dir(exec_env, opts.bids_dir, opts.participant_label)\n",
      "  File \"/usr/local/miniconda/lib/python3.7/site-packages/fmriprep/utils/bids.py\", line 146, in validate_input_dir\n",
      "    subprocess.check_call(['bids-validator', bids_dir, '-c', temp.name])\n",
      "  File \"/usr/local/miniconda/lib/python3.7/subprocess.py\", line 341, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['bids-validator', PosixPath('/bids'), '-c', '/tmp/tmpshxg9mis']' returned non-zero exit status 1.\n",
      "Sentry is attempting to send 0 pending error messages\n",
      "Waiting up to 2 seconds\n",
      "Press Ctrl-C to quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print that one\n",
    "job.ShowOutput(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of them didn't meet the bids spec. I would have known that if I had run the dataset through the bids validator first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
